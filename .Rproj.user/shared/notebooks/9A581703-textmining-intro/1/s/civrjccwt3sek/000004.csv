"0","# prepare x"
"0","data_train_x <- texts_to_sequences(tokenizer, data_train$text_clean) %>%"
"0","  pad_sequences(maxlen = maxlen)"
"0",""
"0","data_val_x <- texts_to_sequences(tokenizer, data_val$text_clean) %>%"
"0","  pad_sequences(maxlen = maxlen)"
"0",""
"0","data_test_x <- texts_to_sequences(tokenizer, data_test$text_clean) %>%"
"0","  pad_sequences(maxlen = maxlen)"
"0",""
"0","# prepare y"
"0","data_train_y <- to_categorical(data_train$label, num_classes = 3)"
"0","data_val_y <- to_categorical(data_val$label, num_classes = 3)"
"0","data_test_y <- to_categorical(data_test$label, num_classes = 3)"
