"0","# initiate keras model sequence"
"0","model <- keras_model_sequential()"
"0",""
"0","# model"
"0","model %>%"
"0","  # layer input"
"0","  layer_embedding("
"0","    name = ""input"","
"0","    input_dim = num_words,"
"0","    input_length = maxlen,"
"0","    output_dim = 32, "
"0","    embeddings_initializer = initializer_random_uniform(minval = -0.05, maxval = 0.05, seed = 2)"
"0","  ) %>%"
"0","  # layer dropout"
"0","  layer_dropout("
"0","    name = ""embedding_dropout"","
"0","    rate = 0.5"
"0","  ) %>%"
"0","  # layer lstm 1"
"0","  layer_lstm("
"0","    name = ""lstm"","
"0","    units = 256,"
"0","    dropout = 0.2,"
"0","    recurrent_dropout = 0.2,"
"0","    return_sequences = FALSE, "
"0","    recurrent_initializer = initializer_random_uniform(minval = -0.05, maxval = 0.05, seed = 2),"
"0","    kernel_initializer = initializer_random_uniform(minval = -0.05, maxval = 0.05, seed = 2)"
"0","  ) %>%"
"0","  # layer output"
"0","  layer_dense("
"0","    name = ""output"","
"0","    units = 3,"
"0","    activation = ""softmax"", "
"0","    kernel_initializer = initializer_random_uniform(minval = -0.05, maxval = 0.05, seed = 2)"
"0","  )"
